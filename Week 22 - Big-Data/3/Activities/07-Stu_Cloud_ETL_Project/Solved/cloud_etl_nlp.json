{"paragraphs":[{"title":"","text":"%md\n### Load in data from S3","user":"anonymous","dateUpdated":"2019-02-04T20:04:37+0000","config":{"editorHide":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Load in data from S3</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1549310677641_-1499376162","id":"20190204-194410_1672343470","dateCreated":"2019-02-04T20:04:37+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:235"},{"title":"","text":"%pyspark\nfrom pyspark import SparkFiles\n# Load in user_data.csv from S3 into a DataFrame\nurl = \"https://s3.amazonaws.com//dataviz-curriculum/day_3/ratings_and_sentiments.csv\"\nspark.sparkContext.addFile(url)\n\ndf = spark.read.option('header', 'true').csv(SparkFiles.get(\"ratings_and_sentiments.csv\"), inferSchema=True, sep=',', timestampFormat=\"mm/dd/yy\")\ndf.show(10)","user":"anonymous","dateUpdated":"2019-02-04T20:04:48+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false}}],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------------------+-----------------+----------+----------+---------+------------+---------+--------+------------+------------+----------+------------+-------------+------------+-----------+---------+----------+-------------+----------+\n|    coffee_shop_name|         review_text|           rating|num_rating|cat_rating|bool_HIGH|overall_sent|vibe_sent|tea_sent|service_sent|seating_sent|price_sent|parking_sent|location_sent|alcohol_sent|coffee_sent|food_sent|hours_sent|internet_sent|local_sent|\n+--------------------+--------------------+-----------------+----------+----------+---------+------------+---------+--------+------------+------------+----------+------------+-------------+------------+-----------+---------+----------+-------------+----------+\n|The Factory - Caf...|11/25/2016 1 chec...| 5.0 star rating |         5|      HIGH|        1|           4|        3|       0|           0|           0|         0|           0|            0|           1|          3|        0|         0|            0|         0|\n|The Factory - Caf...|12/2/2016 Listed ...| 4.0 star rating |         4|      HIGH|        1|           3|        3|       0|           0|           0|         0|           0|            0|           0|          0|        2|         0|            0|         0|\n|The Factory - Caf...|11/30/2016 1 chec...| 4.0 star rating |         4|      HIGH|        1|           2|        2|       0|           0|           3|         0|           0|            0|           0|         -1|        2|         0|            0|         0|\n|The Factory - Caf...|11/25/2016 Very c...| 2.0 star rating |         2|       LOW|        0|           1|        0|       0|           0|          -1|        -1|           0|            0|           0|          0|        0|         0|            0|         0|\n|The Factory - Caf...|12/3/2016 1 check...| 4.0 star rating |         4|      HIGH|        1|           2|        0|       0|           0|           0|         0|           3|            0|           0|          0|        0|         0|            0|         0|\n|The Factory - Caf...|11/20/2016 1 chec...| 4.0 star rating |         4|      HIGH|        1|           0|        2|       0|           0|           0|        -2|           0|            0|           0|          0|        0|         0|           -1|         0|\n|The Factory - Caf...|\"10/27/2016 2 che...| 4.0 star rating |         4|      HIGH|        1|           3|        0|       0|           0|           2|         0|           0|            0|           0|          1|        1|         1|            0|         0|\n|The Factory - Caf...|\"11/2/2016 2 chec...| 5.0 star rating |         5|      HIGH|        1|           0|        1|       0|           1|          -1|         0|           1|            1|           0|         -1|        0|         0|            0|         0|\n|The Factory - Caf...|\"10/25/2016 1 che...| 3.0 star rating |         3|       LOW|        0|           3|        3|       0|           0|           0|         1|           0|            0|           0|          0|        2|         0|            1|         0|\n|The Factory - Caf...|11/10/2016 3 chec...| 5.0 star rating |         5|      HIGH|        1|           3|        1|       0|           0|           0|         0|           0|            0|           0|          1|        0|         0|            0|         0|\n+--------------------+--------------------+-----------------+----------+----------+---------+------------+---------+--------+------------+------------+----------+------------+-------------+------------+-----------+---------+----------+-------------+----------+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1549310677656_1647973768","id":"20190204-194410_1654516797","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:236","dateFinished":"2019-02-04T20:05:31+0000","dateStarted":"2019-02-04T20:04:48+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=0","http://172.17.0.2:4040/jobs/job?id=1","http://172.17.0.2:4040/jobs/job?id=2"],"interpreterSettingId":"spark"}}},{"title":"","text":"%md\n### Transform DataFrame to fit review_rating table","user":"anonymous","dateUpdated":"2019-02-04T20:04:37+0000","config":{"editorHide":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Transform DataFrame to fit review_rating table</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1549310677656_-622202022","id":"20190204-194410_574950996","dateCreated":"2019-02-04T20:04:37+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:237"},{"title":"","text":"%pyspark\nreview_df = df.select([\"review_text\",\"num_rating\"])\nreview_df.show()","user":"anonymous","dateUpdated":"2019-02-04T20:05:56+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false}}],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------+\n|         review_text|num_rating|\n+--------------------+----------+\n|11/25/2016 1 chec...|         5|\n|12/2/2016 Listed ...|         4|\n|11/30/2016 1 chec...|         4|\n|11/25/2016 Very c...|         2|\n|12/3/2016 1 check...|         4|\n|11/20/2016 1 chec...|         4|\n|\"10/27/2016 2 che...|         4|\n|\"11/2/2016 2 chec...|         5|\n|\"10/25/2016 1 che...|         3|\n|11/10/2016 3 chec...|         5|\n|\"10/22/2016 1 che...|         4|\n|11/20/2016 The st...|         3|\n|11/17/2016 1 chec...|         3|\n|12/5/2016 This is...|         5|\n|11/13/2016 Beauti...|         5|\n|11/9/2016 1 check...|         5|\n|11/6/2016 Really ...|         5|\n|10/25/2016 1 chec...|         4|\n|10/15/2016 1 chec...|         4|\n|12/1/2016 So much...|         4|\n+--------------------+----------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1549310677659_-1660706318","id":"20190204-194410_781800749","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:238","dateFinished":"2019-02-04T20:05:56+0000","dateStarted":"2019-02-04T20:05:56+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=3"],"interpreterSettingId":"spark"}}},{"title":"","text":"%pyspark\nfrom pyspark.sql.functions import regexp_extract, length\nreview_df = df.withColumn(\"date\", regexp_extract(\"review_text\", \"\\d+/\\d+/\\d+\", 0))\\\n      .withColumn(\"review_text\", regexp_extract(\"review_text\", \"\\d+/\\d+/\\d+(?:\\s)(.*)\", 1))\\\n      .withColumnRenamed(\"num_rating\", \"label\")\\\n      .select([\"label\", \"date\", \"review_text\"])\nreview_df = review_df.withColumn('review_length', length(review_df['review_text'])).dropna()\nreview_df.cache()\nreview_df.show()","user":"anonymous","dateUpdated":"2019-02-04T20:05:59+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false}}],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+----------+--------------------+-------------+\n|label|      date|         review_text|review_length|\n+-----+----------+--------------------+-------------+\n|    5|11/25/2016|1 check-in Love l...|          542|\n|    4| 12/2/2016|Listed in Date Ni...|          279|\n|    4|11/30/2016|1 check-in Listed...|         1240|\n|    2|11/25/2016|Very cool vibe! G...|          364|\n|    4| 12/3/2016|1 check-in They a...|          629|\n|    4|11/20/2016|1 check-in Very c...|          999|\n|    4|10/27/2016|2 check-ins Liste...|         1326|\n|    5| 11/2/2016|2 check-ins Love ...|         1780|\n|    3|10/25/2016|1 check-in Ok let...|         1805|\n|    5|11/10/2016|3 check-ins This ...|          725|\n|    4|10/22/2016|1 check-in Listed...|         1669|\n|    3|11/20/2016|The store has A+ ...|          509|\n|    3|11/17/2016|1 check-in Listed...|          835|\n|    5| 12/5/2016|This is such a cu...|          152|\n|    5|11/13/2016|Beautiful eccentr...|          378|\n|    5| 11/9/2016|1 check-in Listed...|         1452|\n|    5| 11/6/2016|Really love the v...|          395|\n|    4|10/25/2016|1 check-in Check ...|          778|\n|    4|10/15/2016|1 check-in Note: ...|          843|\n|    4| 12/1/2016|So much aesthetic...|          215|\n+-----+----------+--------------------+-------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1549310677660_1494587803","id":"20190204-194410_857053378","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:239","dateFinished":"2019-02-04T20:06:03+0000","dateStarted":"2019-02-04T20:05:59+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=4"],"interpreterSettingId":"spark"}}},{"title":"","text":"%md\n### Create Data Pipeline","user":"anonymous","dateUpdated":"2019-02-04T20:04:37+0000","config":{"editorHide":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Create Data Pipeline</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1549310677662_1833627643","id":"20190204-194410_1055155865","dateCreated":"2019-02-04T20:04:37+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:240"},{"title":"","text":"%pyspark\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n# Create all the features to the data set\ntokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"token_text\")\nstopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\nhashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\nidf = IDF(inputCol='hash_token', outputCol='idf_token')","user":"anonymous","dateUpdated":"2019-02-04T20:06:06+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1549310677663_-1365110205","id":"20190204-194410_878311615","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:241","dateFinished":"2019-02-04T20:06:06+0000","dateStarted":"2019-02-04T20:06:06+0000"},{"title":"","text":"%pyspark\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.linalg import Vector\n\n# Create feature vectors\nclean_up = VectorAssembler(inputCols=['idf_token', 'review_length'], outputCol='features')","user":"anonymous","dateUpdated":"2019-02-04T20:06:09+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1549310677663_-355751687","id":"20190204-194410_1343087396","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:242","dateFinished":"2019-02-04T20:06:09+0000","dateStarted":"2019-02-04T20:06:09+0000"},{"title":"","text":"%pyspark\n# Create and run a data processing Pipeline\nfrom pyspark.ml import Pipeline\ndata_prep_pipeline = Pipeline(stages=[tokenizer, stopremove, hashingTF, idf, clean_up])","user":"anonymous","dateUpdated":"2019-02-04T20:06:12+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1549310677664_-916632751","id":"20190204-194410_1329701487","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:243","dateFinished":"2019-02-04T20:06:12+0000","dateStarted":"2019-02-04T20:06:12+0000"},{"title":"","text":"%md\n### Transform DataFrame","user":"anonymous","dateUpdated":"2019-02-04T20:04:37+0000","config":{"editorHide":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Transform DataFrame</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1549310677665_1384808001","id":"20190204-194410_1384961456","dateCreated":"2019-02-04T20:04:37+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:244"},{"title":"","text":"%pyspark\n# Fit and transform the pipeline\ncleaner = data_prep_pipeline.fit(review_df)\ncleaned = cleaner.transform(review_df)","user":"anonymous","dateUpdated":"2019-02-04T20:06:15+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1549310677666_-294344841","id":"20190204-194410_694895454","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:245","dateFinished":"2019-02-04T20:06:23+0000","dateStarted":"2019-02-04T20:06:15+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=5","http://172.17.0.2:4040/jobs/job?id=6"],"interpreterSettingId":"spark"}}},{"title":"","text":"%pyspark\n# Show label of ham spame and resulting features\ncleaned.select(['label', 'features']).show()","user":"anonymous","dateUpdated":"2019-02-04T20:06:28+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false}}],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|    5|(262145,[9639,991...|\n|    4|(262145,[512,1588...|\n|    4|(262145,[3578,963...|\n|    2|(262145,[9639,157...|\n|    4|(262145,[3294,736...|\n|    4|(262145,[14,8443,...|\n|    4|(262145,[14,604,3...|\n|    5|(262145,[14,4543,...|\n|    3|(262145,[3890,392...|\n|    5|(262145,[991,2437...|\n|    4|(262145,[14,326,3...|\n|    3|(262145,[6922,736...|\n|    3|(262145,[6922,963...|\n|    5|(262145,[4081,158...|\n|    5|(262145,[1076,199...|\n|    5|(262145,[14,329,1...|\n|    5|(262145,[14,1998,...|\n|    4|(262145,[14,5281,...|\n|    4|(262145,[7388,963...|\n|    4|(262145,[9639,158...|\n+-----+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1549310677667_2089009535","id":"20190204-194410_381718932","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:246","dateFinished":"2019-02-04T20:06:29+0000","dateStarted":"2019-02-04T20:06:28+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=7"],"interpreterSettingId":"spark"}}},{"title":"","text":"%md\n### Run NaiveBayes","user":"anonymous","dateUpdated":"2019-02-04T20:04:37+0000","config":{"editorHide":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Run NaiveBayes</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1549310677668_1748951772","id":"20190204-194410_1422920697","dateCreated":"2019-02-04T20:04:37+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:247"},{"title":"","text":"%pyspark\nfrom pyspark.ml.classification import NaiveBayes\n# Break data down into a training set and a testing set\ntraining, testing = cleaned.randomSplit([0.7, 0.3])\n\n# Create a Naive Bayes model and fit training data\nnb = NaiveBayes()\npredictor = nb.fit(training)","user":"anonymous","dateUpdated":"2019-02-04T20:06:32+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false}}],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1549310677669_-224622551","id":"20190204-194410_1623549318","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248","dateFinished":"2019-02-04T20:06:55+0000","dateStarted":"2019-02-04T20:06:32+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=8","http://172.17.0.2:4040/jobs/job?id=9"],"interpreterSettingId":"spark"}}},{"title":"","text":"%pyspark\n# Tranform the model with the testing data\ntest_results = predictor.transform(testing)\ntest_results.show(5)","user":"anonymous","dateUpdated":"2019-02-04T20:06:59+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false}}],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+---------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n|label|     date|         review_text|review_length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n+-----+---------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n|    1|1/14/2016|Worst brownie I h...|          103|[worst, brownie, ...|[worst, brownie, ...|(262144,[9639,244...|(262144,[9639,244...|(262145,[9639,244...|[-860.96252687915...|[3.47901680025850...|       3.0|\n|    1|1/16/2016|Red haired woman ...|           88|[red, haired, wom...|[red, haired, wom...|(262144,[13471,21...|(262144,[13471,21...|(262145,[13471,21...|[-650.72597784987...|[1.04624967634073...|       4.0|\n|    1|1/22/2016|Updated review Ca...|          331|[updated, review,...|[updated, review,...|(262144,[14,9616,...|(262144,[14,9616,...|(262145,[14,9616,...|[-1951.0514884790...|[5.45991257531376...|       4.0|\n|    1|1/25/2016|This is just for ...|          514|[this, is, just, ...|[peanut, butter, ...|(262144,[2835,420...|(262144,[2835,420...|(262145,[2835,420...|[-3331.4876191131...|[3.08915448566889...|       3.0|\n|    1|1/26/2015|Updated review Ba...|         1013|[updated, review,...|[updated, review,...|(262144,[2710,311...|(262144,[2710,311...|(262145,[2710,311...|[-7077.6217024287...|[6.66120305621585...|       4.0|\n+-----+---------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1549310677669_-1083180051","id":"20190204-194410_331856755","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:249","dateFinished":"2019-02-04T20:07:08+0000","dateStarted":"2019-02-04T20:06:59+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=10"],"interpreterSettingId":"spark"}}},{"title":"","text":"%md\n### Predict accuract of the model","user":"anonymous","dateUpdated":"2019-02-04T20:04:37+0000","config":{"editorHide":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Predict accuract of the model</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1549310677670_1301175470","id":"20190204-194410_18470062","dateCreated":"2019-02-04T20:04:37+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:250"},{"title":"","text":"%pyspark\n# Use the Class Evaluator for a cleaner description\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nacc_eval = MulticlassClassificationEvaluator()\nacc = acc_eval.evaluate(test_results)\nprint(\"Accuracy of model at predicting reviews was: %f\" % acc)","user":"anonymous","dateUpdated":"2019-02-04T20:07:12+0000","config":{"selectedInterpreter":{"name":"spark.pyspark","profile":"pyspark","isCustom":false,"editorLanguage":"python","className":"org.apache.zeppelin.spark.PySparkInterpreter","isDefault":false},"colWidth":12,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false}}],"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Accuracy of model at predicting reviews was: 0.158201\n"}]},"apps":[],"jobName":"paragraph_1549310677672_-1880983587","id":"20190204-194410_1438816439","dateCreated":"2019-02-04T20:04:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:251","dateFinished":"2019-02-04T20:07:30+0000","dateStarted":"2019-02-04T20:07:12+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=11","http://172.17.0.2:4040/jobs/job?id=12","http://172.17.0.2:4040/jobs/job?id=13"],"interpreterSettingId":"spark"}}},{"title":"","text":"","user":"anonymous","dateUpdated":"2019-02-04T20:04:37+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1549310677673_-897924050","id":"20190204-194754_2111881530","dateCreated":"2019-02-04T20:04:37+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:252"}],"name":"cloud_etl_nlp","id":"2E3UDGGHK","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}